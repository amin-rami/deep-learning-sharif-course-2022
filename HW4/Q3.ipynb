{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "669fc95e",
   "metadata": {},
   "source": [
    "# Mohammad Amin Rami\n",
    "# 98101588\n",
    "# HW4\n",
    "# Question 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e2ccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, AutoModel, BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6da069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_poets = [\n",
    "    'amir_norm.txt',\n",
    "    'anvari_norm.txt',\n",
    "    'bahar_norm.txt',\n",
    "    'bidel_norm.txt',\n",
    "    'ferdousi_norm.txt',\n",
    "    'khaghani_norm.txt',\n",
    "    'salman_norm.txt',\n",
    "    'shahnematollah_norm.txt',\n",
    "    'moulavi_norm.txt',\n",
    "    'khosro_norm.txt'\n",
    "]\n",
    "poet_names = [name.split('_')[0] for name in list_of_poets]\n",
    "data_dir = 'normalized'\n",
    "\n",
    "def create_dataset(data_dir, list_of_poets, max_beyts):\n",
    "    data = []\n",
    "    for text_path in list_of_poets:\n",
    "        data_path = os.path.join(data_dir, text_path)\n",
    "        poet_name = text_path.split('_')[0]\n",
    "        count = 0\n",
    "        with open(data_path) as file:\n",
    "            for line in file:\n",
    "                if line.strip() == '':\n",
    "                    continue\n",
    "                data.append((line.strip(), poet_name))\n",
    "                count += 1\n",
    "                if count >= max_beyts:\n",
    "                    break\n",
    "    return data\n",
    "\n",
    "max_beyts = 10000\n",
    "data = create_dataset(data_dir, list_of_poets, max_beyts)\n",
    "random.shuffle(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89ff118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.8\n",
    "k = 1/3\n",
    "train_size = int(ratio * len(data))\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f39375",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {name: i for i, name in enumerate(poet_names)}\n",
    "\n",
    "class Poem(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.labels_map = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = [sample[0] for sample in data]\n",
    "        self.labels = [self.labels_map[sample[1]] for sample in data]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.tokenizer(self.texts[index], padding='max_length', max_length = 25, truncation=True, return_tensors=\"pt\")\n",
    "        label = self.labels[index]\n",
    "        return text, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37394f7c",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5098c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, train_bert):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(\"HooshvareLab/bert-fa-base-uncased\").to(device)\n",
    "        self.train_bert = train_bert\n",
    "        if not train_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(768, 384),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(384, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "        ).to(device)\n",
    "        self.relu = nn.ReLU().to(device)\n",
    "    \n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        linear_output = self.linear(pooled_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a4223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, train_data, test_data, tokenizer, learning_rate, batch_size, epochs):\n",
    "\n",
    "    train, test = Poem(train_data, tokenizer), Poem(test_data, tokenizer)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if model.train_bert:\n",
    "        optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "    else:\n",
    "        optimizer = Adam(model.linear.parameters(), lr= learning_rate)\n",
    "\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_test = 0\n",
    "            total_loss_test = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for test_input, test_label in test_dataloader:\n",
    "                    test_label = test_label.to(device)\n",
    "                    mask = test_input['attention_mask'].to(device)\n",
    "                    input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, test_label.long())\n",
    "                    total_loss_test += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "                    total_acc_test += acc\n",
    "            \n",
    "            print(f'Epochs: {epoch_num + 1}')\n",
    "            print(f'| Train Accuracy: {total_acc_train / len(train_data)*100: .2f}%')\n",
    "            print(f'| Train Loss: {total_loss_train/len(train_dataloader.dataset)}')\n",
    "            print(f'| Test Accuracy: {total_acc_test / len(test_data)*100: .2f}%')\n",
    "            print(f'| Test Loss: {total_loss_test/len(test_dataloader.dataset)}')\n",
    "            print('-'*30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7c39731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_classifier = BertClassifier(train_bert=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b55b0b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2500/2500 [04:46<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1\n",
      "| Train Accuracy:  21.15%\n",
      "| Train Loss: 0.06836959511339664\n",
      "| Test Accuracy:  23.85%\n",
      "| Test Loss: 0.06699122292995453\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2500/2500 [04:47<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2\n",
      "| Train Accuracy:  24.87%\n",
      "| Train Loss: 0.06642915264219046\n",
      "| Test Accuracy:  25.79%\n",
      "| Test Loss: 0.0659926131606102\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2500/2500 [04:47<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3\n",
      "| Train Accuracy:  25.88%\n",
      "| Train Loss: 0.0658469932422042\n",
      "| Test Accuracy:  25.83%\n",
      "| Test Loss: 0.06595951482653618\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2500/2500 [04:46<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4\n",
      "| Train Accuracy:  26.36%\n",
      "| Train Loss: 0.0654714984819293\n",
      "| Test Accuracy:  26.07%\n",
      "| Test Loss: 0.06543723168373108\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train(bert_classifier, train_data, test_data, tokenizer, learning_rate=1e-4, batch_size=32, epochs=4)\n",
    "except KeyboardInterrupt:\n",
    "    print('Training Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4675859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(model, test_data, tokenizer):\n",
    "    test_set = Poem(test_data, tokenizer)\n",
    "    test_dataloader = DataLoader(test_set, batch_size=256)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    total_acc_test = 0\n",
    "    total_loss_test = 0\n",
    "    pred = None\n",
    "    g_truth = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_input, test_label in test_dataloader:\n",
    "            test_label = test_label.to(device)\n",
    "            if g_truth is None:\n",
    "                g_truth = test_label\n",
    "            else:\n",
    "                g_truth = torch.cat((g_truth, test_label))\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            batch_loss = criterion(output, test_label.long())\n",
    "            total_loss_test += batch_loss.item()\n",
    "            if pred is None:\n",
    "                pred = output.argmax(dim=1)\n",
    "            else:\n",
    "                pred = torch.cat((pred, output.argmax(dim=1)))\n",
    "        print(f'Test Loss:     {total_loss_test/len(test_dataloader.dataset)}')\n",
    "        print(classification_report(g_truth.cpu(), pred.cpu()))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daec479e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Classification Report ===========\n",
      "Test Loss:     0.008276267462968827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.03      0.04      2064\n",
      "           1       0.00      0.00      0.00      1990\n",
      "           2       0.21      0.46      0.29      1968\n",
      "           3       0.49      0.61      0.54      2006\n",
      "           4       0.44      0.68      0.54      2022\n",
      "           5       0.21      0.20      0.20      2001\n",
      "           6       0.16      0.66      0.26      1921\n",
      "           7       0.00      0.00      0.00      2027\n",
      "           8       0.00      0.00      0.00      2030\n",
      "           9       0.00      0.00      0.00      1971\n",
      "\n",
      "    accuracy                           0.26     20000\n",
      "   macro avg       0.16      0.26      0.19     20000\n",
      "weighted avg       0.16      0.26      0.19     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/milad/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/milad/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('=========== Classification Report ===========')\n",
    "metrics(bert_classifier, test_data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "133c7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bert_classifier, 'feature_extractor_bert.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08abbe88",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa596545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7cb1d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at HooshvareLab/distilbert-fa-zwnj-base were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/distilbert-fa-zwnj-base and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_bert = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'HooshvareLab/distilbert-fa-zwnj-base',\n",
    "    num_labels=10\n",
    ").to(device)\n",
    "tokenizer_fine = DistilBertTokenizer.from_pretrained(\n",
    "    'HooshvareLab/distilbert-fa-zwnj-base'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd488098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "learning_rate = 3e-5\n",
    "batch_size = 4\n",
    "epochs = 3\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(fine_tuned_bert.parameters(), lr=learning_rate, eps=1e-8)\n",
    "train_dataloader = DataLoader(Poem(train_data, tokenizer_fine), batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(Poem(test_data, tokenizer_fine), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b597010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    for X, y in tqdm(dataloader):\n",
    "        losses = []\n",
    "        # forward prop\n",
    "        y = y.to(device)\n",
    "        mask = X['attention_mask'].to(device)\n",
    "        input_id = X['input_ids'].squeeze(1).to(device)\n",
    "        output = model(\n",
    "            input_ids=input_id,\n",
    "            attention_mask=mask,\n",
    "            labels=y)\n",
    "        loss = output.loss\n",
    "        logits = output.logits\n",
    "        losses.append(loss.item())\n",
    "        num_correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "        # back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    accuracy = num_correct / size\n",
    "    print(f'| Train Loss: {loss.item()}')\n",
    "    print(f'| Train Accuracy: {np.round(accuracy*100,2)}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289da618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            y = y.to(device)\n",
    "            mask = X['attention_mask'].to(device)\n",
    "            input_id = X['input_ids'].squeeze(1).to(device)\n",
    "            output = model(\n",
    "                input_ids=input_id,\n",
    "                attention_mask=mask,\n",
    "                labels=y)\n",
    "            logits = output.logits\n",
    "            num_correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "                        \n",
    "    accuracy = num_correct / size\n",
    "    print(f'| Test Accuracy: {np.round(accuracy*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8e15ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 20000/20000 [25:34<00:00, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss: 1.2594010829925537\n",
      "| Train Accuracy: 51.39%\n",
      "| Test Accuracy: 58.35%\n",
      "\n",
      "Epochs: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 20000/20000 [25:35<00:00, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss: 0.9723908305168152\n",
      "| Train Accuracy: 66.66%\n",
      "| Test Accuracy: 63.68%\n",
      "\n",
      "Epochs: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 20000/20000 [25:39<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Train Loss: 0.8917829990386963\n",
      "| Train Accuracy: 74.5%\n",
      "| Test Accuracy: 64.04%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, epochs+1):\n",
    "    print(f'Epochs: {i}') \n",
    "    train_loop(train_dataloader, fine_tuned_bert, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, fine_tuned_bert, loss_fn)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbe334b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(model, dataloader):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    g_truth  = None\n",
    "    pred = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            y = y.to(device)\n",
    "            if g_truth is None:\n",
    "                g_truth = y\n",
    "            else:\n",
    "                g_truth = torch.cat((g_truth, y))\n",
    "            mask = X['attention_mask'].to(device)\n",
    "            input_id = X['input_ids'].squeeze(1).to(device)\n",
    "            output = model(\n",
    "                input_ids=input_id,\n",
    "                attention_mask=mask,\n",
    "                labels=y)\n",
    "            logits = output.logits\n",
    "            if pred is None:\n",
    "                pred = logits.argmax(dim=1)\n",
    "            else:\n",
    "                pred = torch.cat((pred,  logits.argmax(dim=1)))\n",
    "    accuracy = (pred == g_truth).sum().item()/pred.shape[0]\n",
    "    print(f'| Test Accuracy: {np.round(accuracy*100, 2)}%')\n",
    "    print(classification_report(g_truth.cpu(), pred.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8746565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Classification Report ===========\n",
      "| Test Accuracy: 64.04%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.62      1944\n",
      "           1       0.52      0.48      0.50      2041\n",
      "           2       0.58      0.52      0.55      2005\n",
      "           3       0.79      0.87      0.83      1994\n",
      "           4       0.91      0.88      0.89      2010\n",
      "           5       0.49      0.49      0.49      2023\n",
      "           6       0.49      0.48      0.49      1993\n",
      "           7       0.76      0.75      0.75      2017\n",
      "           8       0.78      0.70      0.74      1989\n",
      "           9       0.48      0.65      0.55      1984\n",
      "\n",
      "    accuracy                           0.64     20000\n",
      "   macro avg       0.65      0.64      0.64     20000\n",
      "weighted avg       0.65      0.64      0.64     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('=========== Classification Report ===========')\n",
    "metrics(fine_tuned_bert, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4bc813",
   "metadata": {},
   "source": [
    "### Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69db2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_preplexity(model, dataloader):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_correct = 0\n",
    "    probs = []\n",
    "    soft = nn.Softmax(dim=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (X, y) in enumerate(dataloader):\n",
    "            y = y.to(device)\n",
    "            mask = X['attention_mask'].to(device)\n",
    "            input_id = X['input_ids'].squeeze(1).to(device)\n",
    "            output = model(\n",
    "                input_ids=input_id,\n",
    "                attention_mask=mask,\n",
    "                labels=y)\n",
    "            logits = output.logits\n",
    "            x = soft(logits)\n",
    "            for i, indx in enumerate(y):\n",
    "                probs.append(x[i, indx])\n",
    "    probs = torch.Tensor(probs)\n",
    "    probs = probs.log()\n",
    "    prob = -1 * probs.sum()/probs.shape[0]\n",
    "    return torch.exp(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c127299",
   "metadata": {},
   "outputs": [],
   "source": [
    "untuned_preplexity = fine_tune_preplexity(untuned_bert, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1faaa058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Preplexity =========\n",
      "Preplexity of model before fine tuning:    12.3135415\n"
     ]
    }
   ],
   "source": [
    "print('========= Preplexity =========')\n",
    "print(f'Preplexity of model before fine tuning:    {fine_tune_preplexity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "698a84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_preplexity = fine_tune_preplexity(fine_tuned_bert, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1f24665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Preplexity =========\n",
      "Preplexity of model after fine tuning:    3.008049249649048\n"
     ]
    }
   ],
   "source": [
    "print('========= Preplexity =========')\n",
    "print(f'Preplexity of model after fine tuning:    {fine_tune_preplexity}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

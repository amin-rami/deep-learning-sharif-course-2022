{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fd31e3",
   "metadata": {},
   "source": [
    "# Mohammad Amin Rami\n",
    "\n",
    "# Student ID: 98101588\n",
    "## Deep Learning HW3\n",
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "905a2de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e8a213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02af0b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(label):\n",
    "    y = torch.zeros((10,))\n",
    "    y[label] = 1\n",
    "    return y.to(device)\n",
    "\n",
    "batch_size = 16\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./Data', \n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=lambda x: transformer(x).to(device),\n",
    "    target_transform=one_hot\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./Data',\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=lambda x: transformer(x).to(device),\n",
    "    target_transform=one_hot\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6c34bc",
   "metadata": {},
   "source": [
    "### Part A: Trining the teacher using a pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a232f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "resnet50 = resnet50(weights='IMAGENET1K_V1').to(device)\n",
    "\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "in_num = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(in_num, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af3c438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "teacher_optimizer = torch.optim.Adam(resnet50.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17cf2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()     \n",
    "    \n",
    "        if batch % 64 * 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>11f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b8c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82944d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss:    2.328330  [    0/50000]\n",
      "loss:    0.984811  [ 4096/50000]\n",
      "loss:    0.909545  [ 8192/50000]\n",
      "loss:    0.689388  [12288/50000]\n",
      "loss:    0.813920  [16384/50000]\n",
      "loss:    0.700437  [20480/50000]\n",
      "loss:    0.761752  [24576/50000]\n",
      "loss:    0.470369  [28672/50000]\n",
      "loss:    0.647181  [32768/50000]\n",
      "loss:    0.836232  [36864/50000]\n",
      "loss:    0.461987  [40960/50000]\n",
      "loss:    0.895684  [45056/50000]\n",
      "loss:    0.638397  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.2%, Avg loss: 0.629915 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss:    0.551104  [    0/50000]\n",
      "loss:    0.397680  [ 4096/50000]\n",
      "loss:    0.742310  [ 8192/50000]\n",
      "loss:    0.544798  [12288/50000]\n",
      "loss:    0.596137  [16384/50000]\n",
      "loss:    0.520657  [20480/50000]\n",
      "loss:    0.464992  [24576/50000]\n",
      "loss:    0.715164  [28672/50000]\n",
      "loss:    0.799786  [32768/50000]\n",
      "loss:    0.457682  [36864/50000]\n",
      "loss:    0.991606  [40960/50000]\n",
      "loss:    0.387928  [45056/50000]\n",
      "loss:    0.455101  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.588297 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss:    0.681936  [    0/50000]\n",
      "loss:    0.448469  [ 4096/50000]\n",
      "loss:    0.357558  [ 8192/50000]\n",
      "loss:    0.749079  [12288/50000]\n",
      "loss:    0.621562  [16384/50000]\n",
      "loss:    0.495338  [20480/50000]\n",
      "loss:    0.527079  [24576/50000]\n",
      "loss:    0.697839  [28672/50000]\n",
      "loss:    0.454448  [32768/50000]\n",
      "loss:    0.574703  [36864/50000]\n",
      "loss:    0.531590  [40960/50000]\n",
      "loss:    0.638311  [45056/50000]\n",
      "loss:    0.550233  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.575918 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss:    0.460101  [    0/50000]\n",
      "loss:    0.644191  [ 4096/50000]\n",
      "loss:    0.700905  [ 8192/50000]\n",
      "loss:    0.665227  [12288/50000]\n",
      "loss:    0.695135  [16384/50000]\n",
      "loss:    0.547878  [20480/50000]\n",
      "loss:    0.306698  [24576/50000]\n",
      "loss:    0.596870  [28672/50000]\n",
      "loss:    0.407175  [32768/50000]\n",
      "loss:    0.404539  [36864/50000]\n",
      "loss:    0.647017  [40960/50000]\n",
      "loss:    0.484870  [45056/50000]\n",
      "loss:    0.684293  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.575128 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss:    0.617382  [    0/50000]\n",
      "loss:    0.475900  [ 4096/50000]\n",
      "loss:    0.364326  [ 8192/50000]\n",
      "loss:    0.606280  [12288/50000]\n",
      "loss:    0.566732  [16384/50000]\n",
      "loss:    0.773436  [20480/50000]\n",
      "loss:    0.417030  [24576/50000]\n",
      "loss:    0.572383  [28672/50000]\n",
      "loss:    0.613500  [32768/50000]\n",
      "loss:    0.661996  [36864/50000]\n",
      "loss:    0.518203  [40960/50000]\n",
      "loss:    0.568536  [45056/50000]\n",
      "loss:    0.453829  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.587852 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, resnet50, loss_fn, teacher_optimizer)\n",
    "    teacher_acc = test_loop(testloader, resnet50, loss_fn)\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f787bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Teacher Performance Report =======\n",
      "The accuracy achieved for teacher model is: 79.75%\n"
     ]
    }
   ],
   "source": [
    "print('======= Teacher Performance Report =======')\n",
    "print(f'The accuracy achieved for teacher model is: {teacher_acc*100:0.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d767f405",
   "metadata": {},
   "source": [
    "--- \n",
    "**As it is shown, an accuracy of approximately 80% percent is achieved for teacher**     \n",
    "using a pre-trained model makes the training phase faster because we only have to train the last layer of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc68ffd2",
   "metadata": {},
   "source": [
    "### Part B: Training the student using teacher-student training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6ded4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "resnet18 = resnet18(weights='IMAGENET1K_V1').to(device)\n",
    "\n",
    "in_num = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(in_num, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245dc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(y, tau):\n",
    "    y_exp = torch.exp(y/tau)\n",
    "    return y_exp/torch.reshape(torch.sum(y_exp, dim=1), (-1, 1))\n",
    "\n",
    "def teacher_student_loss_fn(student, teacher, X, y, alpha, tau, batch_size):\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    pred = student(X)\n",
    "    t_pred = teacher(X)\n",
    "    loss = alpha * tau * tau * (-1) * torch.sum(softmax(t_pred, tau) * softmax(pred, tau).log2()) + (1-alpha)*ce(pred, y)\n",
    "    return loss/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58eb964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_loop(dataloader, student, teacher, loss_fn, optimizer, alpha, tau, batch_size):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        loss = loss_fn(student, teacher, X, y, alpha, tau, batch_size)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()     \n",
    "    \n",
    "        if batch % 64 *100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>11f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45078e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "student_optimizer = torch.optim.Adam(resnet18.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4240aa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss:    0.207074  [    0/50000]\n",
      "loss:    0.162495  [ 4096/50000]\n",
      "loss:    0.193539  [ 8192/50000]\n",
      "loss:    0.207572  [12288/50000]\n",
      "loss:    0.246111  [16384/50000]\n",
      "loss:    0.206524  [20480/50000]\n",
      "loss:    0.198682  [24576/50000]\n",
      "loss:    0.196588  [28672/50000]\n",
      "loss:    0.202725  [32768/50000]\n",
      "loss:    0.200311  [36864/50000]\n",
      "loss:    0.177496  [40960/50000]\n",
      "loss:    0.164825  [45056/50000]\n",
      "loss:    0.217797  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.454565 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss:    0.192510  [    0/50000]\n",
      "loss:    0.158930  [ 4096/50000]\n",
      "loss:    0.209561  [ 8192/50000]\n",
      "loss:    0.174529  [12288/50000]\n",
      "loss:    0.202334  [16384/50000]\n",
      "loss:    0.237954  [20480/50000]\n",
      "loss:    0.192443  [24576/50000]\n",
      "loss:    0.162217  [28672/50000]\n",
      "loss:    0.211491  [32768/50000]\n",
      "loss:    0.213350  [36864/50000]\n",
      "loss:    0.166758  [40960/50000]\n",
      "loss:    0.184743  [45056/50000]\n",
      "loss:    0.201246  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.431779 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss:    0.205978  [    0/50000]\n",
      "loss:    0.177469  [ 4096/50000]\n",
      "loss:    0.218452  [ 8192/50000]\n",
      "loss:    0.182105  [12288/50000]\n",
      "loss:    0.181015  [16384/50000]\n",
      "loss:    0.197260  [20480/50000]\n",
      "loss:    0.212113  [24576/50000]\n",
      "loss:    0.189591  [28672/50000]\n",
      "loss:    0.177592  [32768/50000]\n",
      "loss:    0.211219  [36864/50000]\n",
      "loss:    0.204788  [40960/50000]\n",
      "loss:    0.173144  [45056/50000]\n",
      "loss:    0.204539  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.439277 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss:    0.165910  [    0/50000]\n",
      "loss:    0.177385  [ 4096/50000]\n",
      "loss:    0.200991  [ 8192/50000]\n",
      "loss:    0.220008  [12288/50000]\n",
      "loss:    0.177688  [16384/50000]\n",
      "loss:    0.183151  [20480/50000]\n",
      "loss:    0.188769  [24576/50000]\n",
      "loss:    0.196830  [28672/50000]\n",
      "loss:    0.222508  [32768/50000]\n",
      "loss:    0.136793  [36864/50000]\n",
      "loss:    0.189463  [40960/50000]\n",
      "loss:    0.138789  [45056/50000]\n",
      "loss:    0.163509  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.442812 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss:    0.174523  [    0/50000]\n",
      "loss:    0.213318  [ 4096/50000]\n",
      "loss:    0.141490  [ 8192/50000]\n",
      "loss:    0.166157  [12288/50000]\n",
      "loss:    0.171873  [16384/50000]\n",
      "loss:    0.167874  [20480/50000]\n",
      "loss:    0.203793  [24576/50000]\n",
      "loss:    0.185222  [28672/50000]\n",
      "loss:    0.165386  [32768/50000]\n",
      "loss:    0.142387  [36864/50000]\n",
      "loss:    0.161283  [40960/50000]\n",
      "loss:    0.143451  [45056/50000]\n",
      "loss:    0.201053  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.434998 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "alpha = 0.2\n",
    "tau = 1\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    ts_train_loop(trainloader, resnet18, resnet50, teacher_student_loss_fn, student_optimizer, alpha, tau, batch_size)\n",
    "    student_acc = test_loop(testloader, resnet18, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac0871",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**As it can be seen, using the teacher-student trainig model has caused an improvement in the student**  \n",
    "**The setudent has achieved an accuracy of 87% which better than the teacher itself**     \n",
    "This because the student uses both the training data and the knowledge of the teacher and this causes an improvemnt to the student's performance.      \n",
    "I have chosen the following hyperparameters:     \n",
    "1. alpha = 0.2    \n",
    "2. tau = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65934774",
   "metadata": {},
   "source": [
    "### Part C: Training the student without the teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb535a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18\n",
    "resnet18 = resnet18().to(device)\n",
    "\n",
    "in_num = resnet18.fc.in_features\n",
    "resnet18.fc = nn.Linear(in_num, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f459f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet18.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a063f133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss:    2.439258  [    0/50000]\n",
      "loss:    1.816784  [ 4096/50000]\n",
      "loss:    1.725463  [ 8192/50000]\n",
      "loss:    1.761023  [12288/50000]\n",
      "loss:    1.556396  [16384/50000]\n",
      "loss:    1.303082  [20480/50000]\n",
      "loss:    1.299468  [24576/50000]\n",
      "loss:    1.155498  [28672/50000]\n",
      "loss:    1.231911  [32768/50000]\n",
      "loss:    1.314616  [36864/50000]\n",
      "loss:    1.247056  [40960/50000]\n",
      "loss:    1.054740  [45056/50000]\n",
      "loss:    0.972304  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 63.7%, Avg loss: 1.009833 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss:    0.859626  [    0/50000]\n",
      "loss:    1.002671  [ 4096/50000]\n",
      "loss:    0.686511  [ 8192/50000]\n",
      "loss:    0.967483  [12288/50000]\n",
      "loss:    0.846845  [16384/50000]\n",
      "loss:    0.872856  [20480/50000]\n",
      "loss:    0.819767  [24576/50000]\n",
      "loss:    0.786501  [28672/50000]\n",
      "loss:    0.824263  [32768/50000]\n",
      "loss:    0.743037  [36864/50000]\n",
      "loss:    0.589118  [40960/50000]\n",
      "loss:    0.860406  [45056/50000]\n",
      "loss:    0.706413  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.727447 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss:    0.657897  [    0/50000]\n",
      "loss:    0.958217  [ 4096/50000]\n",
      "loss:    0.505933  [ 8192/50000]\n",
      "loss:    0.723772  [12288/50000]\n",
      "loss:    0.552989  [16384/50000]\n",
      "loss:    0.587360  [20480/50000]\n",
      "loss:    0.618459  [24576/50000]\n",
      "loss:    0.595397  [28672/50000]\n",
      "loss:    0.661951  [32768/50000]\n",
      "loss:    0.601783  [36864/50000]\n",
      "loss:    0.390963  [40960/50000]\n",
      "loss:    0.718862  [45056/50000]\n",
      "loss:    0.678511  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.618317 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss:    0.435142  [    0/50000]\n",
      "loss:    0.541897  [ 4096/50000]\n",
      "loss:    0.416334  [ 8192/50000]\n",
      "loss:    0.439362  [12288/50000]\n",
      "loss:    0.648630  [16384/50000]\n",
      "loss:    0.603076  [20480/50000]\n",
      "loss:    0.553177  [24576/50000]\n",
      "loss:    0.504568  [28672/50000]\n",
      "loss:    0.358704  [32768/50000]\n",
      "loss:    0.439361  [36864/50000]\n",
      "loss:    0.618076  [40960/50000]\n",
      "loss:    0.498625  [45056/50000]\n",
      "loss:    0.252254  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.547356 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss:    0.499822  [    0/50000]\n",
      "loss:    0.560728  [ 4096/50000]\n",
      "loss:    0.443189  [ 8192/50000]\n",
      "loss:    0.364762  [12288/50000]\n",
      "loss:    0.247697  [16384/50000]\n",
      "loss:    0.314088  [20480/50000]\n",
      "loss:    0.440814  [24576/50000]\n",
      "loss:    0.405342  [28672/50000]\n",
      "loss:    0.166479  [32768/50000]\n",
      "loss:    0.241403  [36864/50000]\n",
      "loss:    0.321082  [40960/50000]\n",
      "loss:    0.458387  [45056/50000]\n",
      "loss:    0.357846  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 0.527923 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, resnet18, loss_fn, optimizer)\n",
    "    acc = test_loop(testloader, resnet18, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff2afc",
   "metadata": {},
   "source": [
    "---\n",
    "**We have a achieved a weaker performance comparing to teacher-student model**    \n",
    "This demonstrate the power of teacher-student model. Here we have achieved an accuracy of 82%      \n",
    "So if the student trains on it's own, it will get a weaker result compared to having a teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043cfb9",
   "metadata": {},
   "source": [
    "### Part D: Training Resnet50 from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7081bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51fc2728",
   "metadata": {},
   "outputs": [],
   "source": [
    "res50 = resnet50().to(device)\n",
    "\n",
    "in_num = res50.fc.in_features\n",
    "res50.fc = nn.Linear(in_num, 10)\n",
    "res50 = res50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b73e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "res50_optimizer = torch.optim.Adam(res50.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf400a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss:    1.618962  [    0/50000]\n",
      "loss:    2.052775  [ 1024/50000]\n",
      "loss:    1.653041  [ 2048/50000]\n",
      "loss:    1.568250  [ 3072/50000]\n",
      "loss:    1.672568  [ 4096/50000]\n",
      "loss:    1.429227  [ 5120/50000]\n",
      "loss:    1.280605  [ 6144/50000]\n",
      "loss:    1.797416  [ 7168/50000]\n",
      "loss:    1.569487  [ 8192/50000]\n",
      "loss:    1.667472  [ 9216/50000]\n",
      "loss:    1.542448  [10240/50000]\n",
      "loss:    1.350139  [11264/50000]\n",
      "loss:    1.543443  [12288/50000]\n",
      "loss:    1.187486  [13312/50000]\n",
      "loss:    1.166818  [14336/50000]\n",
      "loss:    1.905272  [15360/50000]\n",
      "loss:    1.716818  [16384/50000]\n",
      "loss:    1.563241  [17408/50000]\n",
      "loss:    1.590838  [18432/50000]\n",
      "loss:    1.363685  [19456/50000]\n",
      "loss:    1.655000  [20480/50000]\n",
      "loss:    1.484124  [21504/50000]\n",
      "loss:    1.602441  [22528/50000]\n",
      "loss:    1.625207  [23552/50000]\n",
      "loss:    1.465005  [24576/50000]\n",
      "loss:    1.337627  [25600/50000]\n",
      "loss:    1.249995  [26624/50000]\n",
      "loss:    1.209847  [27648/50000]\n",
      "loss:    1.334068  [28672/50000]\n",
      "loss:    1.865869  [29696/50000]\n",
      "loss:    1.995640  [30720/50000]\n",
      "loss:    1.152850  [31744/50000]\n",
      "loss:    1.302077  [32768/50000]\n",
      "loss:    0.709862  [33792/50000]\n",
      "loss:    1.258478  [34816/50000]\n",
      "loss:    1.806656  [35840/50000]\n",
      "loss:    1.500686  [36864/50000]\n",
      "loss:    1.562843  [37888/50000]\n",
      "loss:    1.153223  [38912/50000]\n",
      "loss:    1.354849  [39936/50000]\n",
      "loss:    1.651686  [40960/50000]\n",
      "loss:    1.561014  [41984/50000]\n",
      "loss:    1.432076  [43008/50000]\n",
      "loss:    0.845088  [44032/50000]\n",
      "loss:    1.221735  [45056/50000]\n",
      "loss:    1.634232  [46080/50000]\n",
      "loss:    1.196934  [47104/50000]\n",
      "loss:    0.876786  [48128/50000]\n",
      "loss:    1.230773  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 57.2%, Avg loss: 1.215040 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss:    1.023534  [    0/50000]\n",
      "loss:    0.921787  [ 1024/50000]\n",
      "loss:    0.955803  [ 2048/50000]\n",
      "loss:    0.929810  [ 3072/50000]\n",
      "loss:    1.259077  [ 4096/50000]\n",
      "loss:    0.906138  [ 5120/50000]\n",
      "loss:    1.679199  [ 6144/50000]\n",
      "loss:    0.957066  [ 7168/50000]\n",
      "loss:    1.322994  [ 8192/50000]\n",
      "loss:    1.247794  [ 9216/50000]\n",
      "loss:    1.141733  [10240/50000]\n",
      "loss:    1.194734  [11264/50000]\n",
      "loss:    1.055461  [12288/50000]\n",
      "loss:    0.598170  [13312/50000]\n",
      "loss:    1.119330  [14336/50000]\n",
      "loss:    1.013420  [15360/50000]\n",
      "loss:    0.680559  [16384/50000]\n",
      "loss:    1.328348  [17408/50000]\n",
      "loss:    1.220056  [18432/50000]\n",
      "loss:    0.902480  [19456/50000]\n",
      "loss:    0.716671  [20480/50000]\n",
      "loss:    0.754971  [21504/50000]\n",
      "loss:    1.152248  [22528/50000]\n",
      "loss:    1.105971  [23552/50000]\n",
      "loss:    1.055042  [24576/50000]\n",
      "loss:    1.105052  [25600/50000]\n",
      "loss:    1.069681  [26624/50000]\n",
      "loss:    0.824237  [27648/50000]\n",
      "loss:    0.782568  [28672/50000]\n",
      "loss:    0.538307  [29696/50000]\n",
      "loss:    0.997802  [30720/50000]\n",
      "loss:    1.049731  [31744/50000]\n",
      "loss:    1.387383  [32768/50000]\n",
      "loss:    0.860085  [33792/50000]\n",
      "loss:    0.920042  [34816/50000]\n",
      "loss:    0.608158  [35840/50000]\n",
      "loss:    0.713701  [36864/50000]\n",
      "loss:    0.841785  [37888/50000]\n",
      "loss:    1.110193  [38912/50000]\n",
      "loss:    0.579920  [39936/50000]\n",
      "loss:    0.459316  [40960/50000]\n",
      "loss:    0.955606  [41984/50000]\n",
      "loss:    1.552765  [43008/50000]\n",
      "loss:    0.473599  [44032/50000]\n",
      "loss:    0.651523  [45056/50000]\n",
      "loss:    0.757504  [46080/50000]\n",
      "loss:    0.945944  [47104/50000]\n",
      "loss:    1.286681  [48128/50000]\n",
      "loss:    0.738068  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.896676 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss:    0.707888  [    0/50000]\n",
      "loss:    0.644015  [ 1024/50000]\n",
      "loss:    1.148832  [ 2048/50000]\n",
      "loss:    0.751828  [ 3072/50000]\n",
      "loss:    1.436719  [ 4096/50000]\n",
      "loss:    0.495292  [ 5120/50000]\n",
      "loss:    0.375750  [ 6144/50000]\n",
      "loss:    1.002313  [ 7168/50000]\n",
      "loss:    0.513885  [ 8192/50000]\n",
      "loss:    0.237266  [ 9216/50000]\n",
      "loss:    1.011482  [10240/50000]\n",
      "loss:    0.682482  [11264/50000]\n",
      "loss:    0.999575  [12288/50000]\n",
      "loss:    1.011767  [13312/50000]\n",
      "loss:    1.208171  [14336/50000]\n",
      "loss:    1.233195  [15360/50000]\n",
      "loss:    0.500935  [16384/50000]\n",
      "loss:    1.036758  [17408/50000]\n",
      "loss:    0.569435  [18432/50000]\n",
      "loss:    0.551471  [19456/50000]\n",
      "loss:    0.756691  [20480/50000]\n",
      "loss:    0.775089  [21504/50000]\n",
      "loss:    0.451180  [22528/50000]\n",
      "loss:    0.515912  [23552/50000]\n",
      "loss:    1.041863  [24576/50000]\n",
      "loss:    0.779555  [25600/50000]\n",
      "loss:    0.609841  [26624/50000]\n",
      "loss:    1.176215  [27648/50000]\n",
      "loss:    0.413502  [28672/50000]\n",
      "loss:    1.199900  [29696/50000]\n",
      "loss:    0.468183  [30720/50000]\n",
      "loss:    0.724914  [31744/50000]\n",
      "loss:    1.300402  [32768/50000]\n",
      "loss:    0.840543  [33792/50000]\n",
      "loss:    1.091875  [34816/50000]\n",
      "loss:    0.593381  [35840/50000]\n",
      "loss:    0.558527  [36864/50000]\n",
      "loss:    0.202549  [37888/50000]\n",
      "loss:    0.375883  [38912/50000]\n",
      "loss:    0.420992  [39936/50000]\n",
      "loss:    0.515778  [40960/50000]\n",
      "loss:    0.632997  [41984/50000]\n",
      "loss:    0.840916  [43008/50000]\n",
      "loss:    0.689321  [44032/50000]\n",
      "loss:    0.740269  [45056/50000]\n",
      "loss:    0.446801  [46080/50000]\n",
      "loss:    0.619194  [47104/50000]\n",
      "loss:    0.162004  [48128/50000]\n",
      "loss:    0.860396  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 75.3%, Avg loss: 0.715518 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss:    0.507324  [    0/50000]\n",
      "loss:    0.304148  [ 1024/50000]\n",
      "loss:    0.353098  [ 2048/50000]\n",
      "loss:    0.307913  [ 3072/50000]\n",
      "loss:    0.891837  [ 4096/50000]\n",
      "loss:    0.361754  [ 5120/50000]\n",
      "loss:    0.445428  [ 6144/50000]\n",
      "loss:    0.287849  [ 7168/50000]\n",
      "loss:    0.507133  [ 8192/50000]\n",
      "loss:    0.888859  [ 9216/50000]\n",
      "loss:    1.084781  [10240/50000]\n",
      "loss:    0.404739  [11264/50000]\n",
      "loss:    0.480693  [12288/50000]\n",
      "loss:    0.435152  [13312/50000]\n",
      "loss:    0.606370  [14336/50000]\n",
      "loss:    0.369251  [15360/50000]\n",
      "loss:    0.590526  [16384/50000]\n",
      "loss:    0.939412  [17408/50000]\n",
      "loss:    0.710872  [18432/50000]\n",
      "loss:    0.627032  [19456/50000]\n",
      "loss:    0.518270  [20480/50000]\n",
      "loss:    0.538009  [21504/50000]\n",
      "loss:    0.412621  [22528/50000]\n",
      "loss:    0.509617  [23552/50000]\n",
      "loss:    0.636724  [24576/50000]\n",
      "loss:    0.839265  [25600/50000]\n",
      "loss:    0.282260  [26624/50000]\n",
      "loss:    0.809021  [27648/50000]\n",
      "loss:    0.453415  [28672/50000]\n",
      "loss:    0.799609  [29696/50000]\n",
      "loss:    0.686722  [30720/50000]\n",
      "loss:    0.416684  [31744/50000]\n",
      "loss:    0.716324  [32768/50000]\n",
      "loss:    0.402407  [33792/50000]\n",
      "loss:    0.496576  [34816/50000]\n",
      "loss:    0.461284  [35840/50000]\n",
      "loss:    0.665701  [36864/50000]\n",
      "loss:    0.284718  [37888/50000]\n",
      "loss:    0.905453  [38912/50000]\n",
      "loss:    0.360346  [39936/50000]\n",
      "loss:    0.801127  [40960/50000]\n",
      "loss:    0.386551  [41984/50000]\n",
      "loss:    0.573206  [43008/50000]\n",
      "loss:    0.618620  [44032/50000]\n",
      "loss:    0.460991  [45056/50000]\n",
      "loss:    0.818520  [46080/50000]\n",
      "loss:    0.824638  [47104/50000]\n",
      "loss:    0.776354  [48128/50000]\n",
      "loss:    0.794893  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.654030 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss:    0.341601  [    0/50000]\n",
      "loss:    0.155563  [ 1024/50000]\n",
      "loss:    0.382504  [ 2048/50000]\n",
      "loss:    0.667144  [ 3072/50000]\n",
      "loss:    0.658081  [ 4096/50000]\n",
      "loss:    0.664093  [ 5120/50000]\n",
      "loss:    0.794917  [ 6144/50000]\n",
      "loss:    0.508924  [ 7168/50000]\n",
      "loss:    0.430891  [ 8192/50000]\n",
      "loss:    0.246759  [ 9216/50000]\n",
      "loss:    0.400901  [10240/50000]\n",
      "loss:    0.667830  [11264/50000]\n",
      "loss:    0.459402  [12288/50000]\n",
      "loss:    0.547824  [13312/50000]\n",
      "loss:    0.312060  [14336/50000]\n",
      "loss:    0.169227  [15360/50000]\n",
      "loss:    0.465917  [16384/50000]\n",
      "loss:    0.411218  [17408/50000]\n",
      "loss:    0.461551  [18432/50000]\n",
      "loss:    0.361636  [19456/50000]\n",
      "loss:    0.160205  [20480/50000]\n",
      "loss:    0.282101  [21504/50000]\n",
      "loss:    0.442547  [22528/50000]\n",
      "loss:    0.561575  [23552/50000]\n",
      "loss:    0.587451  [24576/50000]\n",
      "loss:    0.124246  [25600/50000]\n",
      "loss:    0.292775  [26624/50000]\n",
      "loss:    0.386365  [27648/50000]\n",
      "loss:    0.379720  [28672/50000]\n",
      "loss:    0.634975  [29696/50000]\n",
      "loss:    0.374990  [30720/50000]\n",
      "loss:    0.361929  [31744/50000]\n",
      "loss:    0.667735  [32768/50000]\n",
      "loss:    0.306120  [33792/50000]\n",
      "loss:    0.645720  [34816/50000]\n",
      "loss:    0.485176  [35840/50000]\n",
      "loss:    0.647012  [36864/50000]\n",
      "loss:    0.253349  [37888/50000]\n",
      "loss:    0.213176  [38912/50000]\n",
      "loss:    0.542735  [39936/50000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:    0.151452  [40960/50000]\n",
      "loss:    0.499910  [41984/50000]\n",
      "loss:    0.827349  [43008/50000]\n",
      "loss:    0.363077  [44032/50000]\n",
      "loss:    0.325536  [45056/50000]\n",
      "loss:    0.621426  [46080/50000]\n",
      "loss:    0.829272  [47104/50000]\n",
      "loss:    0.403509  [48128/50000]\n",
      "loss:    0.127339  [49152/50000]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.607955 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loop(trainloader, res50, loss_fn, res50_optimizer)\n",
    "    acc = test_loop(testloader, res50, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f0aa1",
   "metadata": {},
   "source": [
    "---\n",
    "**Trainig the teacher from scratch has the following disadvantages:**    \n",
    "    1- makes the training proccess much longer specialy if you have limited computational resources. Using a pre-trained model and tuning it is much more efficient and takes much less time. For example, fine tuning Resnet50 took much less time than training it from scratch    \n",
    "    2- People who have developed the pre-trained model, have probably trained the model several times and thus have chosen the best paramters for that model. Because as you know, training a neural network is stochastic proccess. Because weights are initialized randomly and also optimization algorithms are also stochastic such as SGD. Therefore the people who have developed the pre-trained models have chosen the best hyperparamters and initializations and thus it's better to use their results.     \n",
    "    Thus, it is a good idea to use a pre-tained model.\n",
    "    \n",
    "**As you can see, training Resnet50 from scratch has not improved performance comparing to fine tuning and we have gotten the same result. only we have waited a much longer time for the model to be trained**     \n",
    "Both methods give an accuracy of 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc68d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
